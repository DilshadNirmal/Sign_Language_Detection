{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnx in c:\\users\\dellr\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.13.1)\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\dellr\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from onnx) (1.23.5)\n",
      "Requirement already satisfied: protobuf<4,>=3.20.2 in c:\\users\\dellr\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from onnx) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in c:\\users\\dellr\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from onnx) (4.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import onnx2keras\n",
    "# import onnx\n",
    "# import onnxruntime\n",
    "# import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onnx_model_path = 'model.onnx'\n",
    "# onnx_model = onnx.load(onnx_model_path)\n",
    "# session = onnxruntime.InferenceSession(onnx_model_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the shape of the input tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dim_param: \"batch_size\"\n",
      ", dim_value: 3\n",
      ", dim_value: 640\n",
      ", dim_value: 640\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# input_shape = onnx_model.graph.input[0].type.tensor_type.shape.dim\n",
    "# print(input_shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the input and output names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_name = session.get_inputs()[0].name\n",
    "# output_name = session.get_outputs()[0].name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# batch_size = 5\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define input shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_shape = (batch_size, 3, 640, 640)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate random input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data = np.random.rand(*input_shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert input data to float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data = input_data.astype(np.float32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the model and get the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = session.run([output_name], {input_name: input_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[3.42802668e+00, 6.27042389e+00, 2.01801453e+01, ...,\n",
       "          2.20986396e-01, 1.42545462e-01, 1.38073862e-02],\n",
       "         [1.55465374e+01, 4.47159863e+00, 2.66567421e+01, ...,\n",
       "          1.52917206e-01, 1.31912321e-01, 1.31191611e-02],\n",
       "         [2.37978458e+01, 5.02449608e+00, 3.06673832e+01, ...,\n",
       "          1.33523166e-01, 1.10490948e-01, 2.00689137e-02],\n",
       "         ...,\n",
       "         [5.62398560e+02, 6.24783081e+02, 2.68511353e+02, ...,\n",
       "          4.80864346e-02, 4.18971777e-02, 4.87542748e-02],\n",
       "         [5.94509949e+02, 6.21881653e+02, 2.12504654e+02, ...,\n",
       "          5.57259917e-02, 3.89409959e-02, 3.06630135e-02],\n",
       "         [6.16433228e+02, 6.21471802e+02, 2.24292130e+02, ...,\n",
       "          5.29541671e-02, 2.55040526e-02, 2.89500654e-02]],\n",
       " \n",
       "        [[4.22563553e+00, 6.36664009e+00, 1.94838562e+01, ...,\n",
       "          1.66131943e-01, 1.63018912e-01, 1.22029781e-02],\n",
       "         [1.58482685e+01, 5.29284000e+00, 2.96867485e+01, ...,\n",
       "          1.65421784e-01, 1.01630777e-01, 1.13714635e-02],\n",
       "         [2.35366650e+01, 5.35838890e+00, 3.07226791e+01, ...,\n",
       "          1.30731016e-01, 1.23473525e-01, 1.68431103e-02],\n",
       "         ...,\n",
       "         [5.66829224e+02, 6.24683472e+02, 2.72689209e+02, ...,\n",
       "          4.69964147e-02, 3.68583500e-02, 3.98702621e-02],\n",
       "         [5.95751343e+02, 6.19922241e+02, 2.04638321e+02, ...,\n",
       "          5.48769534e-02, 4.05215621e-02, 2.97482014e-02],\n",
       "         [6.17089600e+02, 6.17349426e+02, 2.03960312e+02, ...,\n",
       "          5.46744466e-02, 2.71181166e-02, 3.09163034e-02]],\n",
       " \n",
       "        [[3.85644674e+00, 6.28441906e+00, 2.08505726e+01, ...,\n",
       "          1.77065402e-01, 1.40826374e-01, 1.08662546e-02],\n",
       "         [1.47380352e+01, 4.91294479e+00, 2.90115128e+01, ...,\n",
       "          1.72065496e-01, 1.04003310e-01, 1.08949542e-02],\n",
       "         [2.25506248e+01, 4.73510456e+00, 2.96677704e+01, ...,\n",
       "          1.43366933e-01, 9.15326178e-02, 1.54300332e-02],\n",
       "         ...,\n",
       "         [5.64194458e+02, 6.24475098e+02, 2.79566772e+02, ...,\n",
       "          4.56514657e-02, 3.52565348e-02, 3.57927978e-02],\n",
       "         [5.96670715e+02, 6.21810303e+02, 2.23720108e+02, ...,\n",
       "          5.27659357e-02, 3.57370079e-02, 2.40157247e-02],\n",
       "         [6.18250061e+02, 6.20008301e+02, 2.32651352e+02, ...,\n",
       "          5.33579290e-02, 2.15636790e-02, 2.47018039e-02]],\n",
       " \n",
       "        [[3.07317924e+00, 6.09931469e+00, 1.94281082e+01, ...,\n",
       "          2.02961862e-01, 1.79652214e-01, 1.00084841e-02],\n",
       "         [1.49248581e+01, 5.01566505e+00, 2.76146488e+01, ...,\n",
       "          1.58627570e-01, 1.40895069e-01, 1.02787316e-02],\n",
       "         [2.34551811e+01, 5.58932877e+00, 3.00968590e+01, ...,\n",
       "          1.36956155e-01, 1.30901128e-01, 1.35368705e-02],\n",
       "         ...,\n",
       "         [5.70006531e+02, 6.24159790e+02, 2.62907135e+02, ...,\n",
       "          4.08200920e-02, 3.13923359e-02, 3.40116918e-02],\n",
       "         [5.97658508e+02, 6.21091492e+02, 2.08189041e+02, ...,\n",
       "          5.13939857e-02, 3.77438068e-02, 2.78920829e-02],\n",
       "         [6.17294128e+02, 6.20527039e+02, 2.25256134e+02, ...,\n",
       "          5.07726669e-02, 2.39198506e-02, 2.73655355e-02]],\n",
       " \n",
       "        [[3.08450174e+00, 6.21694565e+00, 2.07648544e+01, ...,\n",
       "          1.74941003e-01, 1.15692526e-01, 7.02574849e-03],\n",
       "         [1.48740778e+01, 4.69789791e+00, 2.87490997e+01, ...,\n",
       "          1.56690210e-01, 1.08482569e-01, 7.52282143e-03],\n",
       "         [2.28652954e+01, 4.74464893e+00, 3.02973099e+01, ...,\n",
       "          1.40585542e-01, 1.03834838e-01, 1.62738562e-02],\n",
       "         ...,\n",
       "         [5.67350830e+02, 6.24325684e+02, 2.56595581e+02, ...,\n",
       "          4.72609699e-02, 3.77307236e-02, 4.09957170e-02],\n",
       "         [5.94998047e+02, 6.21734192e+02, 2.13775696e+02, ...,\n",
       "          6.08973801e-02, 4.20888066e-02, 3.09448838e-02],\n",
       "         [6.17809570e+02, 6.20757080e+02, 2.32250839e+02, ...,\n",
       "          5.64124286e-02, 2.49020159e-02, 2.57273316e-02]]], dtype=float32)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the ONNX model to Keras .h5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'onnx2keras' has no attribute 'common'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m k_model \u001b[39m=\u001b[39m onnx2keras\u001b[39m.\u001b[39monnx_to_keras(onnx_model, [\u001b[39m'\u001b[39m\u001b[39minput\u001b[39m\u001b[39m'\u001b[39m], verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, name_policy\u001b[39m=\u001b[39monnx2keras\u001b[39m.\u001b[39;49mcommon\u001b[39m.\u001b[39msimple_name_policy)\n\u001b[0;32m      3\u001b[0m k_model\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39mmodel.h5\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'onnx2keras' has no attribute 'common'"
     ]
    }
   ],
   "source": [
    "# k_model = onnx2keras.onnx_to_keras(onnx_model, ['input'], verbose=False, name_policy=onnx2keras.common.simple_name_policy)\n",
    "\n",
    "# k_model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import tensorflow as tf\n",
    "import tf2onnx\n",
    "from onnx_tf.backend import prepare"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = onnx.load('model.onnx')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COnvert the ONNX model to a Tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.12.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf2onnx.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_rep = prepare(onnx_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# export to pb file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.pb\\assets\n"
     ]
    }
   ],
   "source": [
    "tf_rep.export_graph('model.pb')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the file permissions to read/write for the owner and read-only for others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chmod('model.pb', 0o644)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the frozen graph from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnknownError",
     "evalue": "NewRandomAccessFile failed to Create/Open: model.pb : Access is denied.\r\n; Input/output error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mGFile(\u001b[39m'\u001b[39m\u001b[39mmodel.pb\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m      3\u001b[0m     graph_def \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mGraphDef()\n\u001b[1;32m----> 4\u001b[0m     graph_def\u001b[39m.\u001b[39mParseFromString(f\u001b[39m.\u001b[39;49mread())\n\u001b[0;32m      6\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m sess:\n\u001b[0;32m      7\u001b[0m     \u001b[39m# Restore the graph\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     sess\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39mas_default()\n",
      "File \u001b[1;32mc:\\Users\\dellr\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:116\u001b[0m, in \u001b[0;36mFileIO.read\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\u001b[39mself\u001b[39m, n\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m    105\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Returns the contents of a file as a string.\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \n\u001b[0;32m    107\u001b[0m \u001b[39m  Starts reading from current position in file.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[39m    string if in string (regular) mode.\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 116\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_preread_check()\n\u001b[0;32m    117\u001b[0m   \u001b[39mif\u001b[39;00m n \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[0;32m    118\u001b[0m     length \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[1;32mc:\\Users\\dellr\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:77\u001b[0m, in \u001b[0;36mFileIO._preread_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read_check_passed:\n\u001b[0;32m     75\u001b[0m   \u001b[39mraise\u001b[39;00m errors\u001b[39m.\u001b[39mPermissionDeniedError(\u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     76\u001b[0m                                      \u001b[39m\"\u001b[39m\u001b[39mFile isn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt open for reading\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 77\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read_buf \u001b[39m=\u001b[39m _pywrap_file_io\u001b[39m.\u001b[39;49mBufferedInputStream(\n\u001b[0;32m     78\u001b[0m     compat\u001b[39m.\u001b[39;49mpath_to_str(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__name), \u001b[39m1024\u001b[39;49m \u001b[39m*\u001b[39;49m \u001b[39m512\u001b[39;49m)\n",
      "\u001b[1;31mUnknownError\u001b[0m: NewRandomAccessFile failed to Create/Open: model.pb : Access is denied.\r\n; Input/output error"
     ]
    }
   ],
   "source": [
    "# Load pb model\n",
    "with tf.io.gfile.GFile('model.pb', 'rb') as f:\n",
    "    graph_def = tf.compat.v1.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    # Restore the graph\n",
    "    sess.graph.as_default()\n",
    "    tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "    # Save as a saved_model\n",
    "    tf.saved_model.save(sess, export_dir='./saved_model')\n",
    "\n",
    "# Load saved_model and save as h5\n",
    "loaded_model = tf.keras.models.load_model('./saved_model')\n",
    "loaded_model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
